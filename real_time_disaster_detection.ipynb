{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR6P34om73pnVBtHrsXidU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derek881107/Real-Time-Disaster-Detection-System/blob/main/real_time_disaster_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Enhanced GDACS Supplier Impact Analysis System ‚Äî Overview\n",
        "==============================================================\n",
        "\n",
        "What this program does\n",
        "----------------------\n",
        "This program monitors global disasters through GDACS (and USGS as backup)\n",
        "and analyzes which suppliers could be affected. It:\n",
        "\n",
        "1. Loads a supplier list from a CSV file.\n",
        "2. Uses the Google Maps API to geocode supplier addresses.\n",
        "3. Fetches disaster alerts from GDACS within a user-defined time window.\n",
        "4. Falls back to USGS earthquake data when needed.\n",
        "5. Calculates distances between disasters and supplier locations.\n",
        "6. Classifies supplier impact levels (Critical / High / Medium / Low).\n",
        "7. Sends a summary email via Gmail and saves a full JSON report.\n",
        "\n",
        "Why it‚Äôs important\n",
        "------------------\n",
        "‚Ä¢ Provides supply chain teams with a quick email alert about which suppliers\n",
        "  may be affected.  \n",
        "‚Ä¢ Creates a detailed JSON report for dashboards, audits, or deeper analysis.  \n",
        "‚Ä¢ Works end-to-end with just a supplier CSV, a Google Maps API key, and a\n",
        "  Gmail App Password.\n",
        "\n",
        "Key features\n",
        "------------\n",
        "‚Ä¢ Parses GDACS alerts with complete metadata (type, severity, coordinates, etc.).  \n",
        "‚Ä¢ Multiple coordinate extraction methods with regex fallbacks.  \n",
        "‚Ä¢ USGS backup feed for earthquake events.  \n",
        "‚Ä¢ Haversine distance-based impact scoring.  \n",
        "‚Ä¢ Email summaries with grouped supplier impacts.  \n",
        "‚Ä¢ JSON reports with metadata, statistics, alerts, and supplier details.\n",
        "\n",
        "What you need before running\n",
        "----------------------------\n",
        "‚Ä¢ Python 3.8+  \n",
        "‚Ä¢ `requests` package  \n",
        "‚Ä¢ Google Maps API key (billing enabled)  \n",
        "‚Ä¢ Gmail account + Gmail App Password  \n",
        "‚Ä¢ Supplier file named `merged_full_dataset.csv`\n",
        "\n",
        "CSV format required\n",
        "-------------------\n",
        "The supplier CSV must include:\n",
        "- id\n",
        "- name\n",
        "- address\n",
        "- country\n",
        "- contact_person\n",
        "- phone\n",
        "- email\n",
        "- product_category\n",
        "- critical_level\n",
        "- type\n",
        "\n",
        "The script auto-detects delimiters (comma, pipe, semicolon, tab).\n",
        "\n",
        "Workflow\n",
        "--------\n",
        "1. Prompt for Gmail and Google Maps API credentials.  \n",
        "2. Load and geocode supplier addresses.  \n",
        "3. Select monitoring period (days) and minimum alert level (Green, Orange, Red).  \n",
        "4. Retrieve alerts from GDACS and USGS.  \n",
        "5. Compute disaster‚Äìsupplier distances.  \n",
        "6. Assign impact levels based on radius thresholds.  \n",
        "7. Output results:\n",
        "   ‚Ä¢ Email: readable disaster + supplier summary.  \n",
        "   ‚Ä¢ JSON: detailed report with metadata and impact analysis.\n",
        "\n",
        "Defaults\n",
        "--------\n",
        "‚Ä¢ Monitoring period: 7 days (max 30).  \n",
        "‚Ä¢ Minimum alert level: Green.  \n",
        "‚Ä¢ Impact radius: 100 km.  \n",
        "‚Ä¢ Supplier CSV: `merged_full_dataset.csv`  \n",
        "‚Ä¢ SMTP: Gmail TLS on port 587.\n",
        "\n",
        "Limitations\n",
        "-----------\n",
        "‚Ä¢ Gmail requires an App Password (not the regular login password).  \n",
        "‚Ä¢ Google Maps API requires billing and quota.  \n",
        "‚Ä¢ Address errors or quota issues prevent geocoding.  \n",
        "‚Ä¢ Secondary effects (e.g., logistics disruptions) are not modeled.  \n",
        "‚Ä¢ USGS backup only supports earthquakes.\n",
        "\n",
        "Security notes\n",
        "--------------\n",
        "‚Ä¢ Do not hardcode credentials in the script or repo.  \n",
        "‚Ä¢ Use interactive input (as provided) or environment variables.  \n",
        "‚Ä¢ Rotate API keys and passwords regularly.\n",
        "\n",
        "Ideas for extension\n",
        "-------------------\n",
        "‚Ä¢ Add more disaster data sources.  \n",
        "‚Ä¢ Save geocoding results to a database.  \n",
        "‚Ä¢ Integrate Slack/Teams notifications.  \n",
        "‚Ä¢ Attach CSV/JSON reports to emails.  \n",
        "‚Ä¢ Automate with schedulers (e.g., daily run).\n",
        "\n",
        "Quick start\n",
        "-----------\n",
        "1. Place `merged_full_dataset.csv` in the working directory.  \n",
        "2. Run the script.  \n",
        "3. Enter Gmail, Gmail App Password, recipient email, and Maps API key.  \n",
        "4. Select monitoring days, minimum alert level, and impact radius.  \n",
        "5. Check your inbox for the alert email and the directory for the JSON report.\n"
      ],
      "metadata": {
        "id": "1AbNFsqXLCNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aQIYzIQJap5",
        "outputId": "cacc05a0-b772-445b-8bca-4ec3764b0367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè≠ ENHANCED GDACS SUPPLIER IMPACT ANALYSIS SYSTEM\n",
            "==========================================================================================\n",
            "üìß Monitors disasters with complete GDACS data and analyzes supplier impact\n",
            "üîç Enhanced Features:\n",
            "   ‚Ä¢ Complete GDACS attribute extraction (all 25+ fields)\n",
            "   ‚Ä¢ Multiple coordinate parsing methods\n",
            "   ‚Ä¢ Enhanced event classification\n",
            "   ‚Ä¢ Backup data sources (USGS)\n",
            "   ‚Ä¢ Improved geocoding and mapping\n",
            "   ‚Ä¢ Supplier type analysis support\n",
            "   ‚Ä¢ User-defined monitoring period\n",
            "==========================================================================================\n",
            "‚úÖ Enhanced GDACS Supplier Impact Analysis System Initialized\n",
            "üè≠ Features: Complete GDACS data extraction + Supplier impact analysis\n",
            "üìä Enhanced with full GDACS attributes support\n",
            "\n",
            "üìù Supplier CSV file not found: merged_full_dataset.csv\n",
            "‚ùå Cannot proceed without supplier data\n",
            "Please ensure your CSV file is named 'merged_full_dataset.csv' and contains the required columns:\n",
            "   id, name, address, country, contact_person, phone, email, product_category, critical_level, type\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Enhanced GDACS System with Complete Data Extraction and Supplier Impact Analysis\n",
        "Monitors fixed supplier list, analyzes disaster impact on suppliers, obtains complete GDACS data\n",
        "\"\"\"\n",
        "\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.header import Header\n",
        "from email.utils import formataddr\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import json\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "from urllib.parse import quote\n",
        "import math\n",
        "\n",
        "\n",
        "class EnhancedGDACSSupplierImpactSystem:\n",
        "    def __init__(self):\n",
        "        self.email_config = None\n",
        "        self.google_maps_api_key = None\n",
        "        self.suppliers = []\n",
        "        print(\"‚úÖ Enhanced GDACS Supplier Impact Analysis System Initialized\")\n",
        "        print(\"üè≠ Features: Complete GDACS data extraction + Supplier impact analysis\")\n",
        "        print(\"üìä Enhanced with full GDACS attributes support\")\n",
        "\n",
        "    def setup_gmail(self, email, password, recipient):\n",
        "        \"\"\"Setup Gmail configuration\"\"\"\n",
        "        self.email_config = {\n",
        "            'server': 'smtp.gmail.com',\n",
        "            'port': 587,\n",
        "            'email': email.strip(),\n",
        "            'password': password.strip(),\n",
        "            'recipient': recipient.strip()\n",
        "        }\n",
        "        print(f\"üì® Sender: {self.email_config['email']}\")\n",
        "        print(f\"üì• Recipient: {self.email_config['recipient']}\")\n",
        "        return True\n",
        "\n",
        "    def setup_google_maps(self, api_key):\n",
        "        \"\"\"Setup Google Maps API key\"\"\"\n",
        "        self.google_maps_api_key = api_key.strip()\n",
        "        print(\"üó∫Ô∏è Google Maps API configured\")\n",
        "        return True\n",
        "\n",
        "    def validate_csv_format(self, csv_file_path):\n",
        "        \"\"\"Validate CSV format and provide correction suggestions\"\"\"\n",
        "        if not os.path.exists(csv_file_path):\n",
        "            print(f\"‚ùå CSV file not found: {csv_file_path}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "                lines = content.split('\\n')\n",
        "\n",
        "                print(\"\\nüîç CSV Format Analysis:\")\n",
        "                print(\"=\"*50)\n",
        "\n",
        "                # Check first few lines\n",
        "                for i, line in enumerate(lines[:3], 1):\n",
        "                    if line.strip():\n",
        "                        comma_count = line.count(',')\n",
        "                        pipe_count = line.count('|')\n",
        "                        semicolon_count = line.count(';')\n",
        "                        quote_count = line.count('\"')\n",
        "\n",
        "                        print(f\"Line {i}: {line[:80]}{'...' if len(line) > 80 else ''}\")\n",
        "                        print(f\"   Commas: {comma_count}, Pipes: {pipe_count}, Semicolons: {semicolon_count}, Quotes: {quote_count}\")\n",
        "\n",
        "                # Reset file pointer and test parsing\n",
        "                file.seek(0)\n",
        "\n",
        "                try:\n",
        "                    reader = csv.DictReader(file)\n",
        "                    header = reader.fieldnames\n",
        "                    first_row = next(reader, None)\n",
        "\n",
        "                    if header and first_row:\n",
        "                        print(f\"\\n‚úÖ Standard CSV parsing successful\")\n",
        "                        print(f\"   Headers: {header}\")\n",
        "                        print(f\"   Field count: {len(header)}\")\n",
        "\n",
        "                        # Check if address field is properly parsed\n",
        "                        if 'address' in first_row:\n",
        "                            address = first_row['address']\n",
        "                            if len(address) < 10:\n",
        "                                print(f\"‚ö†Ô∏è Address seems too short: '{address}'\")\n",
        "                                print(f\"   This might indicate CSV parsing issues\")\n",
        "                            else:\n",
        "                                print(f\"‚úÖ Address field looks good: '{address[:50]}...'\")\n",
        "\n",
        "                        return True\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Standard CSV parsing failed: {e}\")\n",
        "                    return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error analyzing CSV: {e}\")\n",
        "            return False\n",
        "\n",
        "    def load_suppliers_from_csv(self, csv_file_path):\n",
        "        \"\"\"Load supplier list from CSV file - supports addresses with commas\"\"\"\n",
        "        if not os.path.exists(csv_file_path):\n",
        "            print(f\"‚ùå CSV file not found: {csv_file_path}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            suppliers = []\n",
        "\n",
        "            with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
        "                # Detect delimiter\n",
        "                sample = file.read(1024)\n",
        "                file.seek(0)\n",
        "\n",
        "                if sample.count('|') > sample.count(','):\n",
        "                    delimiter = '|'\n",
        "                    print(\"üìù Detected delimiter: | (pipe)\")\n",
        "                elif sample.count(';') > sample.count(','):\n",
        "                    delimiter = ';'\n",
        "                    print(\"üìù Detected delimiter: ; (semicolon)\")\n",
        "                elif sample.count('\\t') > 0:\n",
        "                    delimiter = '\\t'\n",
        "                    print(\"üìù Detected delimiter: \\\\t (tab)\")\n",
        "                else:\n",
        "                    delimiter = ','\n",
        "                    print(\"üìù Detected delimiter: , (comma) - Using quote protection\")\n",
        "\n",
        "                # Read CSV with appropriate settings\n",
        "                if delimiter == ',':\n",
        "                    reader = csv.DictReader(file, delimiter=delimiter, quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "                else:\n",
        "                    reader = csv.DictReader(file, delimiter=delimiter)\n",
        "\n",
        "                for row_num, row in enumerate(reader, 1):\n",
        "                    # Clean field values\n",
        "                    cleaned_row = {}\n",
        "                    for key, value in row.items():\n",
        "                        if key:\n",
        "                            cleaned_key = key.strip()\n",
        "                            cleaned_value = str(value).strip() if value else ''\n",
        "                            cleaned_row[cleaned_key] = cleaned_value\n",
        "\n",
        "                    supplier = {\n",
        "                        'id': cleaned_row.get('id', f'SUP_{row_num:03d}'),\n",
        "                        'name': cleaned_row.get('name', ''),\n",
        "                        'address': cleaned_row.get('address', ''),\n",
        "                        'country': cleaned_row.get('country', ''),\n",
        "                        'contact_person': cleaned_row.get('contact_person', ''),\n",
        "                        'phone': cleaned_row.get('phone', ''),\n",
        "                        'email': cleaned_row.get('email', ''),\n",
        "                        'product_category': cleaned_row.get('product_category', ''),\n",
        "                        'critical_level': cleaned_row.get('critical_level', 'Medium'),\n",
        "                        'type': cleaned_row.get('type', ''),\n",
        "                        'latitude': None,\n",
        "                        'longitude': None,\n",
        "                        'geocoded': False\n",
        "                    }\n",
        "\n",
        "                    # Validate required fields\n",
        "                    if supplier['name'] and supplier['address']:\n",
        "                        suppliers.append(supplier)\n",
        "                        short_address = supplier['address'][:50] + \"...\" if len(supplier['address']) > 50 else supplier['address']\n",
        "                        print(f\"‚úÖ Loaded: {supplier['name']} ({short_address}) - Type: {supplier['type']}\")\n",
        "                    else:\n",
        "                        print(f\"‚ö†Ô∏è Row {row_num}: Missing name or address, skipped\")\n",
        "\n",
        "            self.suppliers = suppliers\n",
        "            print(f\"üìä Total suppliers loaded: {len(self.suppliers)}\")\n",
        "            return len(self.suppliers) > 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading CSV: {e}\")\n",
        "            return False\n",
        "\n",
        "    def geocode_suppliers(self):\n",
        "        \"\"\"Convert supplier addresses to latitude/longitude coordinates\"\"\"\n",
        "        if not self.google_maps_api_key:\n",
        "            print(\"‚ùå Google Maps API key not configured\")\n",
        "            return False\n",
        "\n",
        "        if not self.suppliers:\n",
        "            print(\"‚ùå No suppliers loaded\")\n",
        "            return False\n",
        "\n",
        "        print(\"üó∫Ô∏è Geocoding supplier addresses...\")\n",
        "        geocoded_count = 0\n",
        "\n",
        "        for i, supplier in enumerate(self.suppliers, 1):\n",
        "            if supplier['geocoded']:\n",
        "                print(f\"   {i:2d}. {supplier['name']}: Already geocoded\")\n",
        "                geocoded_count += 1\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                address = f\"{supplier['address']}, {supplier['country']}\"\n",
        "                url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={quote(address)}&key={self.google_maps_api_key}\"\n",
        "\n",
        "                response = requests.get(url, timeout=10)\n",
        "                data = response.json()\n",
        "\n",
        "                if data.get('status') == 'OK' and data.get('results'):\n",
        "                    location = data['results'][0]['geometry']['location']\n",
        "                    supplier['latitude'] = location['lat']\n",
        "                    supplier['longitude'] = location['lng']\n",
        "                    supplier['geocoded'] = True\n",
        "                    geocoded_count += 1\n",
        "\n",
        "                    print(f\"   {i:2d}. {supplier['name']}: ‚úÖ ({location['lat']:.4f}, {location['lng']:.4f})\")\n",
        "                else:\n",
        "                    print(f\"   {i:2d}. {supplier['name']}: ‚ùå Geocoding failed ({data.get('status')})\")\n",
        "\n",
        "                # API rate limiting\n",
        "                time.sleep(0.2)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   {i:2d}. {supplier['name']}: ‚ùå Error - {e}\")\n",
        "\n",
        "        print(f\"üìä Geocoding complete: {geocoded_count}/{len(self.suppliers)} suppliers\")\n",
        "        return geocoded_count > 0\n",
        "\n",
        "    def get_enhanced_gdacs_alerts(self, days=7, min_alert_level='Green'):\n",
        "        \"\"\"Get complete GDACS disaster alert data with level filtering\"\"\"\n",
        "        print(f\"üîç Fetching enhanced GDACS alerts from past {days} days...\")\n",
        "        print(f\"üö® Minimum alert level: {min_alert_level}\")\n",
        "        alerts = []\n",
        "\n",
        "        try:\n",
        "            # Try GDACS RSS feed first\n",
        "            rss_url = \"https://www.gdacs.org/xml/rss.xml\"\n",
        "            print(f\"üì° Connecting to: {rss_url}\")\n",
        "\n",
        "            response = requests.get(rss_url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            root = ET.fromstring(response.content)\n",
        "            since = datetime.now() - timedelta(days=days)\n",
        "            items = root.findall('.//item')\n",
        "            print(f\"üìä Found {len(items)} total RSS items\")\n",
        "\n",
        "            for item in items:\n",
        "                try:\n",
        "                    alert_data = self._parse_enhanced_rss_item(item, since)\n",
        "                    if alert_data and self._meets_alert_level_criteria(alert_data['alert_level'], min_alert_level):\n",
        "                        alerts.append(alert_data)\n",
        "                        print(f\"‚úÖ Added: {alert_data['event_type']} ({alert_data['event_type_short']}) in {alert_data['country']} - {alert_data['alert_level']} Alert\")\n",
        "                    elif alert_data:\n",
        "                        print(f\"‚ö™ Filtered: {alert_data['event_type']} ({alert_data['event_type_short']}) in {alert_data['country']} - {alert_data['alert_level']} Alert (below {min_alert_level} threshold)\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error parsing RSS item: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not alerts:\n",
        "                print(\"üîÑ RSS returned no qualifying alerts, trying backup methods...\")\n",
        "                alerts = self._get_enhanced_backup_alerts(days, min_alert_level)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error fetching RSS: {e}\")\n",
        "            print(\"üîÑ Trying backup methods...\")\n",
        "            alerts = self._get_enhanced_backup_alerts(days, min_alert_level)\n",
        "\n",
        "        print(f\"üìà Total enhanced alerts found (>= {min_alert_level}): {len(alerts)}\")\n",
        "        return alerts\n",
        "\n",
        "    def _parse_enhanced_rss_item(self, item, since_date):\n",
        "        \"\"\"Parse RSS item and extract all GDACS attributes according to official API spec\"\"\"\n",
        "        try:\n",
        "            namespaces = {\n",
        "                'gdacs': 'http://www.gdacs.org',\n",
        "                'georss': 'http://www.georss.org/georss',\n",
        "                'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#'\n",
        "            }\n",
        "\n",
        "            # Basic attributes\n",
        "            title = self._get_text_element(item, 'title', 'Unknown Event')\n",
        "            description = self._get_text_element(item, 'description', '')\n",
        "            pub_date = self._get_text_element(item, 'pubDate', '')\n",
        "            link = self._get_text_element(item, 'link', '')\n",
        "            guid = self._get_text_element(item, 'guid', '')\n",
        "\n",
        "            # Parse publication date\n",
        "            event_date = self._parse_pub_date(pub_date)\n",
        "            if event_date and event_date < since_date:\n",
        "                return None\n",
        "\n",
        "            # GDACS specific attributes (all fields from official API)\n",
        "            gdacs_data = {}\n",
        "            gdacs_elements = [\n",
        "                'alertlevel',      # Alert level (\"Red\", \"Orange\", \"Green\")\n",
        "                'country',         # Country where incident happened\n",
        "                'durationinweek',  # Duration of the incident in full weeks\n",
        "                'eventid',         # Event ID (numerical)\n",
        "                'eventname',       # Short event name\n",
        "                'eventtype',       # Short event type (\"DR\", \"EQ\", \"FL\", \"TC\", \"TS\", \"VO\", \"WF\")\n",
        "                'fromdate',        # Date and time this incident started\n",
        "                'icon',            # Icon URL\n",
        "                'iscurrent',       # Whether this incident is current\n",
        "                'population',      # Exposed population\n",
        "                'severity',        # Severity of the incident\n",
        "                'temporary',       # Whether this incident is temporary\n",
        "                'todate',          # Date and time this incident ended\n",
        "                'version',         # Version of the incident in this feed\n",
        "                'vulnerability'    # Vulnerability score (textual or numerical)\n",
        "            ]\n",
        "\n",
        "            for element in gdacs_elements:\n",
        "                value = self._get_text_element(item, f'gdacs:{element}', None, namespaces)\n",
        "                if value:\n",
        "                    gdacs_data[element] = value\n",
        "\n",
        "            # Geographic information (geometries and coordinates)\n",
        "            coordinates = self._extract_enhanced_coordinates(item, namespaces)\n",
        "\n",
        "            # Process event type (convert short to long form)\n",
        "            event_type_short = gdacs_data.get('eventtype', 'UN')\n",
        "            event_type = self._get_full_event_type(event_type_short)\n",
        "\n",
        "            # Process alert level (GDACS standard: Green, Orange, Red)\n",
        "            alert_level = gdacs_data.get('alertlevel', 'Unknown')\n",
        "            if not alert_level or alert_level == 'Unknown':\n",
        "                alert_level = self._extract_alert_level_from_text(title, description)\n",
        "\n",
        "            # Process country\n",
        "            country = gdacs_data.get('country', 'Unknown')\n",
        "            if not country or country == 'Unknown':\n",
        "                country = self._extract_country_from_text(title, description)\n",
        "\n",
        "            # Get location name (distance_to_home equivalent)\n",
        "            location_name = \"Unknown Location\"\n",
        "            if coordinates['latitude'] and coordinates['longitude']:\n",
        "                location_name = self._get_location_name(coordinates['latitude'], coordinates['longitude'])\n",
        "\n",
        "            # Build complete alert data with all GDACS API fields\n",
        "            enhanced_alert = {\n",
        "                # Basic fields\n",
        "                'title': title,\n",
        "                'description': description,\n",
        "                'external_id': guid,\n",
        "                'attribution': 'GDACS',\n",
        "\n",
        "                # Geographic data\n",
        "                'geometries': coordinates,  # All geometry details\n",
        "                'coordinates': coordinates,  # Best coordinates\n",
        "                'location_name': location_name,\n",
        "\n",
        "                # Alert classification\n",
        "                'category': alert_level,\n",
        "                'alert_level': alert_level,  # Alert level (\"Red\", \"Orange\", \"Green\")\n",
        "\n",
        "                # Event information\n",
        "                'event_type': event_type,\n",
        "                'event_type_short': event_type_short,  # Short event type\n",
        "                'event_id': self._safe_int(gdacs_data.get('eventid')),  # Event ID (numerical)\n",
        "                'event_name': gdacs_data.get('eventname', title),  # Short event name\n",
        "\n",
        "                # Location\n",
        "                'country': country,  # Country where incident happened\n",
        "\n",
        "                # Severity and impact\n",
        "                'severity': gdacs_data.get('severity', 'Unknown'),  # Severity of the incident\n",
        "                'population': self._safe_int(gdacs_data.get('population')),  # Exposed population\n",
        "                'vulnerability': gdacs_data.get('vulnerability', 'Unknown'),  # Vulnerability score\n",
        "\n",
        "                # Timing\n",
        "                'from_date': self._parse_gdacs_date(gdacs_data.get('fromdate')),  # Date/time started\n",
        "                'to_date': self._parse_gdacs_date(gdacs_data.get('todate')),  # Date/time ended\n",
        "                'pub_date': event_date.strftime('%Y-%m-%d %H:%M:%S') if event_date else '',\n",
        "                'duration_in_week': self._safe_int(gdacs_data.get('durationinweek')),  # Duration in weeks\n",
        "\n",
        "                # Status flags\n",
        "                'is_current': gdacs_data.get('iscurrent', '').lower() == 'true',  # Whether current\n",
        "                'temporary': gdacs_data.get('temporary', '').lower() == 'true',  # Whether temporary\n",
        "\n",
        "                # Metadata\n",
        "                'icon_url': gdacs_data.get('icon', ''),  # Icon URL\n",
        "                'version': gdacs_data.get('version', '1'),  # Version in feed\n",
        "                'link': link,\n",
        "                'source': 'GDACS_ENHANCED'\n",
        "            }\n",
        "\n",
        "            return enhanced_alert\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error parsing enhanced RSS item: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _get_enhanced_backup_alerts(self, days, min_alert_level='Green'):\n",
        "        \"\"\"Enhanced backup alert retrieval using USGS with level filtering\"\"\"\n",
        "        print(\"üåç Using enhanced backup data sources...\")\n",
        "        alerts = []\n",
        "        alerts.extend(self._get_usgs_earthquake_data(days, min_alert_level))\n",
        "        return alerts\n",
        "\n",
        "    def _get_usgs_earthquake_data(self, days, min_alert_level='Green'):\n",
        "        \"\"\"Get USGS earthquake data and convert to GDACS format with level filtering\"\"\"\n",
        "        alerts = []\n",
        "\n",
        "        try:\n",
        "            usgs_url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_week.geojson\"\n",
        "            response = requests.get(usgs_url, timeout=30)\n",
        "            data = response.json()\n",
        "\n",
        "            since = datetime.now() - timedelta(days=days)\n",
        "\n",
        "            for feature in data.get('features', []):\n",
        "                try:\n",
        "                    props = feature.get('properties', {})\n",
        "                    coords = feature.get('geometry', {}).get('coordinates', [])\n",
        "\n",
        "                    timestamp = props.get('time')\n",
        "                    if timestamp:\n",
        "                        event_date = datetime.fromtimestamp(timestamp / 1000)\n",
        "                        if event_date < since:\n",
        "                            continue\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    magnitude = props.get('mag', 0)\n",
        "                    if magnitude < 4.5:  # Only focus on larger earthquakes\n",
        "                        continue\n",
        "\n",
        "                    # Determine alert level (GDACS standard: Green, Orange, Red)\n",
        "                    if magnitude >= 7.0:\n",
        "                        alert_level = 'Red'\n",
        "                    elif magnitude >= 6.0:\n",
        "                        alert_level = 'Orange'\n",
        "                    else:\n",
        "                        alert_level = 'Green'\n",
        "\n",
        "                    # Check if alert meets minimum level criteria\n",
        "                    if not self._meets_alert_level_criteria(alert_level, min_alert_level):\n",
        "                        continue\n",
        "\n",
        "                    location_name = \"Unknown Location\"\n",
        "                    country = \"Unknown\"\n",
        "                    if len(coords) > 1:\n",
        "                        location_name = self._get_location_name(coords[1], coords[0])\n",
        "                        country = self._extract_country_from_place(props.get('place', ''))\n",
        "\n",
        "                    earthquake_alert = {\n",
        "                        'title': props.get('title', 'Earthquake Event'),\n",
        "                        'description': f\"Magnitude {magnitude} earthquake - {props.get('place', 'Unknown location')}\",\n",
        "                        'external_id': feature.get('id', ''),\n",
        "                        'attribution': 'USGS',\n",
        "                        'coordinates': {\n",
        "                            'latitude': coords[1] if len(coords) > 1 else None,\n",
        "                            'longitude': coords[0] if len(coords) > 0 else None\n",
        "                        },\n",
        "                        'location_name': location_name,\n",
        "                        'category': alert_level,\n",
        "                        'alert_level': alert_level,\n",
        "                        'event_type': 'Earthquake',\n",
        "                        'event_type_short': 'EQ',\n",
        "                        'country': country,\n",
        "                        'event_id': None,\n",
        "                        'event_name': f\"M{magnitude} {props.get('place', 'Earthquake')}\",\n",
        "                        'severity': str(magnitude),\n",
        "                        'population': None,\n",
        "                        'vulnerability': 'Unknown',\n",
        "                        'from_date': event_date,\n",
        "                        'to_date': None,\n",
        "                        'pub_date': event_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                        'duration_in_week': None,\n",
        "                        'is_current': True,\n",
        "                        'temporary': False,\n",
        "                        'icon_url': '',\n",
        "                        'version': '1',\n",
        "                        'link': props.get('url', ''),\n",
        "                        'source': 'USGS_ENHANCED',\n",
        "                        'magnitude': magnitude,\n",
        "                        'depth': coords[2] if len(coords) > 2 else None\n",
        "                    }\n",
        "\n",
        "                    alerts.append(earthquake_alert)\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            print(f\"üåç USGS enhanced found {len(alerts)} earthquake alerts (>= {min_alert_level})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Enhanced backup failed: {e}\")\n",
        "\n",
        "        return alerts\n",
        "\n",
        "    def _meets_alert_level_criteria(self, alert_level, min_alert_level):\n",
        "        \"\"\"Check if alert level meets minimum criteria\"\"\"\n",
        "        # Define GDACS alert level hierarchy (higher number = more severe)\n",
        "        # Official GDACS levels: Green, Orange, Red only\n",
        "        level_hierarchy = {\n",
        "            'Green': 1,\n",
        "            'Orange': 2,\n",
        "            'Red': 3,\n",
        "            'Unknown': 0  # Unknown alerts are included at Green level\n",
        "        }\n",
        "\n",
        "        alert_value = level_hierarchy.get(alert_level, 0)\n",
        "        min_value = level_hierarchy.get(min_alert_level, 1)\n",
        "\n",
        "        # For Unknown alerts, include them if minimum is Green\n",
        "        if alert_level == 'Unknown' and min_alert_level == 'Green':\n",
        "            return True\n",
        "\n",
        "        return alert_value >= min_value\n",
        "\n",
        "    def _get_alert_level_description(self, level):\n",
        "        \"\"\"Get description for alert level\"\"\"\n",
        "        descriptions = {\n",
        "            'Green': 'Green and above (All alerts)',\n",
        "            'Orange': 'Orange and above (High to severe)',\n",
        "            'Red': 'Red only (Severe only)'\n",
        "        }\n",
        "        return descriptions.get(level, level)\n",
        "\n",
        "    def analyze_supplier_impact(self, disaster_lat, disaster_lon, impact_radius_km=100):\n",
        "        \"\"\"Analyze disaster impact on suppliers\"\"\"\n",
        "        if not self.suppliers:\n",
        "            return []\n",
        "\n",
        "        impacted_suppliers = []\n",
        "\n",
        "        for supplier in self.suppliers:\n",
        "            if not supplier['geocoded']:\n",
        "                continue\n",
        "\n",
        "            distance = self._calculate_distance(\n",
        "                disaster_lat, disaster_lon,\n",
        "                supplier['latitude'], supplier['longitude']\n",
        "            )\n",
        "\n",
        "            if distance <= impact_radius_km:\n",
        "                impact_level = self._determine_impact_level(distance, impact_radius_km)\n",
        "\n",
        "                supplier_impact = supplier.copy()\n",
        "                supplier_impact['distance_km'] = distance\n",
        "                supplier_impact['impact_level'] = impact_level\n",
        "\n",
        "                impacted_suppliers.append(supplier_impact)\n",
        "\n",
        "        # Sort by distance\n",
        "        impacted_suppliers.sort(key=lambda x: x['distance_km'])\n",
        "        return impacted_suppliers\n",
        "\n",
        "    def send_enhanced_supplier_impact_alert(self, alerts, impact_radius=100, days=7, min_alert_level='Green'):\n",
        "        \"\"\"Send enhanced supplier impact analysis report and save JSON\"\"\"\n",
        "        if not self.email_config:\n",
        "            print(\"‚ùå Email configuration not set\")\n",
        "            return False\n",
        "\n",
        "        if not alerts:\n",
        "            print(\"‚ÑπÔ∏è No alerts to send\")\n",
        "            return self._send_no_alerts_notification(days, min_alert_level)\n",
        "\n",
        "        try:\n",
        "            # Generate JSON report\n",
        "            json_data = self._generate_json_report(alerts, impact_radius, days, min_alert_level)\n",
        "            json_saved = self._save_json_report(json_data)\n",
        "\n",
        "            # Build enhanced email content\n",
        "            body = self._build_email_body(alerts, impact_radius, days, min_alert_level)\n",
        "\n",
        "            # Build and send email\n",
        "            total_impacted = self._count_total_impacted_suppliers(alerts, impact_radius)\n",
        "            subject = f\"üö® Enhanced Supplier Impact Alert: {total_impacted} Suppliers Affected | {len(alerts)} Disasters ({days} days, {min_alert_level}+ level)\"\n",
        "\n",
        "            msg = MIMEText(body, 'plain', 'utf-8')\n",
        "            msg['Subject'] = Header(subject, 'utf-8')\n",
        "            msg['From'] = formataddr((\"Enhanced GDACS Supplier Impact System\", self.email_config['email']))\n",
        "            msg['To'] = formataddr((\"Supply Chain Manager\", self.email_config['recipient']))\n",
        "\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['email'], self.email_config['password'])\n",
        "            server.sendmail(self.email_config['email'], self.email_config['recipient'], msg.as_string())\n",
        "            server.quit()\n",
        "\n",
        "            print(\"üìß Enhanced supplier impact alert email sent successfully!\")\n",
        "            if json_saved:\n",
        "                print(\"üíæ JSON report saved successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to send enhanced supplier impact alert: {e}\")\n",
        "            return False\n",
        "\n",
        "    def send_test_email(self):\n",
        "        \"\"\"Send test email\"\"\"\n",
        "        if not self.email_config:\n",
        "            print(\"‚ùå Email configuration not set\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            body = \"‚úÖ Enhanced GDACS Supplier Impact System test is working!\\n\"\n",
        "            body += f\"üìÖ Test time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "            body += f\"üè≠ Monitoring {len(self.suppliers)} suppliers\\n\"\n",
        "            body += f\"üó∫Ô∏è Google Maps API: {'‚úÖ Configured' if self.google_maps_api_key else '‚ùå Not configured'}\\n\"\n",
        "            body += f\"üîß Enhanced Features:\\n\"\n",
        "            body += f\"   ‚Ä¢ Complete GDACS attribute extraction\\n\"\n",
        "            body += f\"   ‚Ä¢ Multiple backup data sources\\n\"\n",
        "            body += f\"   ‚Ä¢ Enhanced coordinate parsing\\n\"\n",
        "            body += f\"   ‚Ä¢ Improved event classification\\n\"\n",
        "            body += f\"   ‚Ä¢ Supplier type analysis support\\n\"\n",
        "            body += f\"   ‚Ä¢ User-defined monitoring period\\n\"\n",
        "\n",
        "            msg = MIMEText(body, 'plain', 'utf-8')\n",
        "            msg['Subject'] = Header(\"‚úÖ Enhanced GDACS Supplier System Test\", 'utf-8')\n",
        "            msg['From'] = formataddr((\"Enhanced GDACS Supplier Impact System\", self.email_config['email']))\n",
        "            msg['To'] = formataddr((\"Supply Chain Manager\", self.email_config['recipient']))\n",
        "\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['email'], self.email_config['password'])\n",
        "            server.sendmail(self.email_config['email'], self.email_config['recipient'], msg.as_string())\n",
        "            server.quit()\n",
        "\n",
        "            print(\"üì¨ Enhanced test email sent successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error sending test email: {e}\")\n",
        "            return False\n",
        "\n",
        "    # Helper methods\n",
        "    def _get_text_element(self, item, tag, default='', namespaces=None):\n",
        "        \"\"\"Safely get XML element text\"\"\"\n",
        "        try:\n",
        "            if namespaces:\n",
        "                element = item.find(tag, namespaces)\n",
        "            else:\n",
        "                element = item.find(tag)\n",
        "            return element.text if element is not None and element.text else default\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    def _parse_pub_date(self, pub_date):\n",
        "        \"\"\"Parse publication date\"\"\"\n",
        "        if not pub_date:\n",
        "            return datetime.now()\n",
        "\n",
        "        try:\n",
        "            formats = [\n",
        "                \"%a, %d %b %Y %H:%M:%S %Z\",\n",
        "                \"%a, %d %b %Y %H:%M:%S\",\n",
        "                \"%Y-%m-%d %H:%M:%S\",\n",
        "                \"%Y-%m-%dT%H:%M:%SZ\",\n",
        "                \"%Y-%m-%dT%H:%M:%S\"\n",
        "            ]\n",
        "\n",
        "            for fmt in formats:\n",
        "                try:\n",
        "                    return datetime.strptime(pub_date[:len(fmt.replace('%Z', ''))], fmt.replace('%Z', ''))\n",
        "                except:\n",
        "                    continue\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return datetime.now()\n",
        "\n",
        "    def _parse_gdacs_date(self, date_str):\n",
        "        \"\"\"Parse GDACS date format\"\"\"\n",
        "        if not date_str:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            formats = [\n",
        "                \"%Y-%m-%dT%H:%M:%SZ\",\n",
        "                \"%Y-%m-%d %H:%M:%S\",\n",
        "                \"%Y-%m-%d\"\n",
        "            ]\n",
        "\n",
        "            for fmt in formats:\n",
        "                try:\n",
        "                    return datetime.strptime(date_str[:len(fmt.replace('Z', ''))], fmt.replace('Z', ''))\n",
        "                except:\n",
        "                    continue\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _safe_int(self, value):\n",
        "        \"\"\"Safely convert to integer\"\"\"\n",
        "        try:\n",
        "            if value:\n",
        "                return int(float(value))\n",
        "        except:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    def _get_full_event_type(self, short_type):\n",
        "        \"\"\"Convert short event type to full name\"\"\"\n",
        "        type_mapping = {\n",
        "            'DR': 'Drought',\n",
        "            'EQ': 'Earthquake',\n",
        "            'FL': 'Flood',\n",
        "            'TC': 'Tropical Cyclone',\n",
        "            'TS': 'Tsunami',\n",
        "            'VO': 'Volcano',\n",
        "            'WF': 'Wild Fire',\n",
        "            'ST': 'Storm',\n",
        "            'CY': 'Cyclone'\n",
        "        }\n",
        "        return type_mapping.get(short_type, short_type)\n",
        "\n",
        "    def _extract_enhanced_coordinates(self, item, namespaces):\n",
        "        \"\"\"Extract enhanced coordinate information\"\"\"\n",
        "        coordinates = {'latitude': None, 'longitude': None}\n",
        "\n",
        "        try:\n",
        "            # Try to get from georss:point\n",
        "            point = self._get_text_element(item, 'georss:point', '', namespaces)\n",
        "            if point:\n",
        "                parts = point.strip().split()\n",
        "                if len(parts) >= 2:\n",
        "                    coordinates['latitude'] = float(parts[0])\n",
        "                    coordinates['longitude'] = float(parts[1])\n",
        "                    return coordinates\n",
        "\n",
        "            # Try to get from geo:lat and geo:long\n",
        "            lat = self._get_text_element(item, 'geo:lat', '', namespaces)\n",
        "            lon = self._get_text_element(item, 'geo:long', '', namespaces)\n",
        "            if lat and lon:\n",
        "                coordinates['latitude'] = float(lat)\n",
        "                coordinates['longitude'] = float(lon)\n",
        "                return coordinates\n",
        "\n",
        "            # Extract from description text\n",
        "            description = self._get_text_element(item, 'description', '')\n",
        "            extracted = self._extract_coordinates_from_text(description)\n",
        "            if extracted['latitude'] and extracted['longitude']:\n",
        "                return extracted\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error extracting coordinates: {e}\")\n",
        "\n",
        "        return coordinates\n",
        "\n",
        "    def _extract_coordinates_from_text(self, text):\n",
        "        \"\"\"Extract coordinates from text\"\"\"\n",
        "        coordinates = {'latitude': None, 'longitude': None}\n",
        "\n",
        "        try:\n",
        "            patterns = [\n",
        "                r'[-+]?\\d+\\.\\d+[,\\s]+[-+]?\\d+\\.\\d+',\n",
        "                r'\\([-+]?\\d+\\.\\d+[,\\s]+[-+]?\\d+\\.\\d+\\)',\n",
        "                r'lat[:\\s]+[-+]?\\d+\\.\\d+[,\\s]+lon[:\\s]+[-+]?\\d+\\.\\d+',\n",
        "                r'latitude[:\\s]+[-+]?\\d+\\.\\d+[,\\s]+longitude[:\\s]+[-+]?\\d+\\.\\d+'\n",
        "            ]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                match = re.search(pattern, text, re.IGNORECASE)\n",
        "                if match:\n",
        "                    coord_str = match.group()\n",
        "                    parsed = self._parse_coordinate_string(coord_str)\n",
        "                    if parsed['latitude'] and parsed['longitude']:\n",
        "                        return parsed\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Coordinate extraction error: {e}\")\n",
        "\n",
        "        return coordinates\n",
        "\n",
        "    def _parse_coordinate_string(self, coord_str):\n",
        "        \"\"\"Parse coordinate string\"\"\"\n",
        "        try:\n",
        "            coord_str = coord_str.replace('(', '').replace(')', '').replace('lat:', '').replace('lon:', '')\n",
        "            coord_str = coord_str.replace('latitude:', '').replace('longitude:', '')\n",
        "\n",
        "            numbers = re.findall(r'[-+]?\\d+\\.\\d+', coord_str)\n",
        "\n",
        "            if len(numbers) >= 2:\n",
        "                lat = float(numbers[0])\n",
        "                lon = float(numbers[1])\n",
        "\n",
        "                if -90 <= lat <= 90 and -180 <= lon <= 180:\n",
        "                    return {'latitude': lat, 'longitude': lon}\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return {'latitude': None, 'longitude': None}\n",
        "\n",
        "    def _extract_alert_level_from_text(self, title, description):\n",
        "        \"\"\"Extract alert level from text (GDACS standard: Green, Orange, Red)\"\"\"\n",
        "        text = f\"{title} {description}\".lower()\n",
        "\n",
        "        if any(word in text for word in ['red', 'severe', 'extreme', 'critical']):\n",
        "            return 'Red'\n",
        "        elif any(word in text for word in ['orange', 'high', 'major']):\n",
        "            return 'Orange'\n",
        "        elif any(word in text for word in ['green', 'low', 'minor', 'medium', 'moderate']):\n",
        "            return 'Green'\n",
        "        else:\n",
        "            return 'Unknown'\n",
        "\n",
        "    def _extract_country_from_text(self, title, description):\n",
        "        \"\"\"Extract country from text\"\"\"\n",
        "        text = f\"{title} {description}\"\n",
        "\n",
        "        countries = [\n",
        "            'China', 'Japan', 'Indonesia', 'Philippines', 'India', 'Turkey', 'Iran', 'Pakistan',\n",
        "            'Chile', 'Peru', 'Mexico', 'Italy', 'Greece', 'Afghanistan', 'Nepal', 'Myanmar',\n",
        "            'Thailand', 'Vietnam', 'Taiwan', 'South Korea', 'North Korea', 'Malaysia', 'Singapore',\n",
        "            'Australia', 'New Zealand', 'Russia', 'United States', 'Canada', 'Brazil', 'Argentina',\n",
        "            'Bangladesh', 'Sri Lanka', 'Cambodia', 'Laos', 'Mongolia', 'Kazakhstan', 'Uzbekistan'\n",
        "        ]\n",
        "\n",
        "        for country in countries:\n",
        "            if country.lower() in text.lower():\n",
        "                return country\n",
        "\n",
        "        return 'Unknown'\n",
        "\n",
        "    def _get_location_name(self, latitude, longitude):\n",
        "        \"\"\"Get location name based on coordinates\"\"\"\n",
        "        if not latitude or not longitude:\n",
        "            return \"Unknown Location\"\n",
        "\n",
        "        try:\n",
        "            url = f\"https://api.bigdatacloud.net/data/reverse-geocode-client?latitude={latitude}&longitude={longitude}&localityLanguage=en\"\n",
        "            response = requests.get(url, timeout=10)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                city = data.get('locality', data.get('city', ''))\n",
        "                region = data.get('principalSubdivision', '')\n",
        "                country = data.get('countryName', '')\n",
        "\n",
        "                location_parts = [part for part in [city, region, country] if part]\n",
        "                if location_parts:\n",
        "                    return ', '.join(location_parts)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "        return f\"Region ({latitude:.1f}¬∞, {longitude:.1f}¬∞)\"\n",
        "\n",
        "    def _extract_country_from_place(self, place):\n",
        "        \"\"\"Extract country from USGS place string\"\"\"\n",
        "        if not place:\n",
        "            return 'Unknown'\n",
        "\n",
        "        parts = place.split(',')\n",
        "        if len(parts) > 1:\n",
        "            last_part = parts[-1].strip()\n",
        "\n",
        "            country_mapping = {\n",
        "                'Japan': 'Japan',\n",
        "                'China': 'China',\n",
        "                'Indonesia': 'Indonesia',\n",
        "                'Philippines': 'Philippines',\n",
        "                'Chile': 'Chile',\n",
        "                'Peru': 'Peru',\n",
        "                'Mexico': 'Mexico',\n",
        "                'Turkey': 'Turkey',\n",
        "                'Iran': 'Iran',\n",
        "                'Greece': 'Greece',\n",
        "                'Italy': 'Italy',\n",
        "                'Alaska': 'United States',\n",
        "                'California': 'United States',\n",
        "                'Nevada': 'United States'\n",
        "            }\n",
        "\n",
        "            for key, value in country_mapping.items():\n",
        "                if key.lower() in last_part.lower():\n",
        "                    return value\n",
        "\n",
        "            return last_part\n",
        "\n",
        "        return self._extract_country_from_text('', place)\n",
        "\n",
        "    def _determine_impact_level(self, distance, max_radius):\n",
        "        \"\"\"Determine impact level based on distance\"\"\"\n",
        "        ratio = distance / max_radius\n",
        "\n",
        "        if ratio <= 0.3:  # Within 30% range\n",
        "            return \"Critical\"\n",
        "        elif ratio <= 0.6:  # Within 60% range\n",
        "            return \"High\"\n",
        "        elif ratio <= 0.8:  # Within 80% range\n",
        "            return \"Medium\"\n",
        "        else:\n",
        "            return \"Low\"\n",
        "\n",
        "    def _calculate_distance(self, lat1, lon1, lat2, lon2):\n",
        "        \"\"\"Calculate distance between two points (kilometers)\"\"\"\n",
        "        if not all([lat1, lon1, lat2, lon2]):\n",
        "            return 999\n",
        "\n",
        "        R = 6371  # Earth radius (kilometers)\n",
        "\n",
        "        lat1_rad = math.radians(lat1)\n",
        "        lat2_rad = math.radians(lat2)\n",
        "        delta_lat = math.radians(lat2 - lat1)\n",
        "        delta_lon = math.radians(lon2 - lon1)\n",
        "\n",
        "        a = (math.sin(delta_lat/2) * math.sin(delta_lat/2) +\n",
        "             math.cos(lat1_rad) * math.cos(lat2_rad) *\n",
        "             math.sin(delta_lon/2) * math.sin(delta_lon/2))\n",
        "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
        "\n",
        "        return R * c\n",
        "\n",
        "    def _build_email_body(self, alerts, impact_radius, days, min_alert_level='Green'):\n",
        "        \"\"\"Build the email body content\"\"\"\n",
        "        body = f\"üè≠ ENHANCED GDACS SUPPLIER IMPACT ANALYSIS REPORT\\n\"\n",
        "        body += f\"{'='*80}\\n\"\n",
        "        body += f\"üìä Total Disasters: {len(alerts)}\\n\"\n",
        "        body += f\"üìÖ Report Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        body += f\"‚è∞ Time Range: Past {days} days\\n\"\n",
        "        body += f\"üö® Alert Level Filter: {self._get_alert_level_description(min_alert_level)}\\n\"\n",
        "        body += f\"üè≠ Monitored Suppliers: {len(self.suppliers)}\\n\"\n",
        "        body += f\"üìè Impact Analysis Radius: {impact_radius}km\\n\"\n",
        "        body += f\"üîß System: Enhanced GDACS with Complete Data Extraction\\n\\n\"\n",
        "\n",
        "        total_impacted_suppliers = 0\n",
        "\n",
        "        # Analyze each disaster event\n",
        "        for i, alert in enumerate(alerts, 1):\n",
        "            coords = alert['coordinates']\n",
        "            alert_emoji = {\n",
        "                'Red': 'üî¥', 'Orange': 'üü†', 'Yellow': 'üü°', 'Green': 'üü¢'\n",
        "            }.get(alert['alert_level'], '‚ö™')\n",
        "\n",
        "            body += f\"{i:2d}. {alert_emoji} {alert['event_type']} ({alert['event_type_short']}) - {alert['alert_level']} Alert\\n\"\n",
        "            body += f\"    üìç Location: {alert.get('location_name', alert['country'])}\\n\"\n",
        "            body += f\"    üè≥Ô∏è Country: {alert['country']}\\n\"\n",
        "            body += f\"    üìù Title: {alert['title']}\\n\"\n",
        "\n",
        "            if alert.get('severity') and alert['severity'] != 'Unknown':\n",
        "                body += f\"    üìä Severity: {alert['severity']}\\n\"\n",
        "\n",
        "            if alert.get('magnitude'):\n",
        "                body += f\"    üìà Magnitude: {alert['magnitude']}\\n\"\n",
        "\n",
        "            # Coordinates and impact analysis\n",
        "            if coords['latitude'] and coords['longitude']:\n",
        "                body += f\"    üó∫Ô∏è **COORDINATES: {coords['latitude']:.4f}¬∞, {coords['longitude']:.4f}¬∞**\\n\"\n",
        "                body += f\"    üåç Google Maps: https://maps.google.com/?q={coords['latitude']},{coords['longitude']}\\n\"\n",
        "\n",
        "                # Analyze supplier impact\n",
        "                impacted_suppliers = self.analyze_supplier_impact(\n",
        "                    coords['latitude'], coords['longitude'], impact_radius\n",
        "                )\n",
        "\n",
        "                if impacted_suppliers:\n",
        "                    total_impacted_suppliers += len(impacted_suppliers)\n",
        "                    body += f\"    üö® **IMPACTED SUPPLIERS: {len(impacted_suppliers)} companies**\\n\\n\"\n",
        "\n",
        "                    # Group by impact level\n",
        "                    impact_groups = {}\n",
        "                    for supplier in impacted_suppliers:\n",
        "                        level = supplier['impact_level']\n",
        "                        if level not in impact_groups:\n",
        "                            impact_groups[level] = []\n",
        "                        impact_groups[level].append(supplier)\n",
        "\n",
        "                    # Display suppliers for each impact level\n",
        "                    for impact_level in ['Critical', 'High', 'Medium', 'Low']:\n",
        "                        if impact_level in impact_groups:\n",
        "                            suppliers_in_level = impact_groups[impact_level]\n",
        "                            impact_emoji = {\n",
        "                                'Critical': 'üî¥', 'High': 'üü†', 'Medium': 'üü°', 'Low': 'üü¢'\n",
        "                            }.get(impact_level, '‚ö™')\n",
        "\n",
        "                            body += f\"       {impact_emoji} {impact_level} Impact ({len(suppliers_in_level)} suppliers):\\n\"\n",
        "\n",
        "                            for supplier in suppliers_in_level:\n",
        "                                critical_marker = \" ‚ö†Ô∏è CRITICAL SUPPLIER\" if supplier['critical_level'] == 'High' else \"\"\n",
        "                                body += f\"         ‚Ä¢ {supplier['name']}{critical_marker}\\n\"\n",
        "                                body += f\"           üìç Address: {supplier['address']}\\n\"\n",
        "                                body += f\"           üìè Distance: {supplier['distance_km']:.1f}km from disaster\\n\"\n",
        "                                body += f\"           üè∑Ô∏è Product Category: {supplier['product_category']}\\n\"\n",
        "                                body += f\"           üîß Type: {supplier['type']}\\n\"\n",
        "                                body += f\"           üìû Contact Person: {supplier['contact_person']}\\n\"\n",
        "                                body += f\"           üìß Email: {supplier['email']}\\n\"\n",
        "                                body += f\"           ‚òéÔ∏è Phone: {supplier['phone']}\\n\\n\"\n",
        "\n",
        "                            body += \"\\n\"\n",
        "                else:\n",
        "                    body += f\"    ‚úÖ **SUPPLIER IMPACT: No suppliers affected within {impact_radius}km**\\n\\n\"\n",
        "            else:\n",
        "                body += f\"    üó∫Ô∏è **COORDINATES: Not available**\\n\"\n",
        "                body += f\"    üè≠ **SUPPLIER ANALYSIS: Cannot perform without coordinates**\\n\\n\"\n",
        "\n",
        "            body += f\"    ‚è∞ Published: {alert['pub_date']}\\n\"\n",
        "            body += f\"    üîó Source: {alert['source']}\\n\"\n",
        "            body += f\"\\n{'-'*70}\\n\\n\"\n",
        "\n",
        "        # Add summary\n",
        "        body += self._build_summary_section(alerts, impact_radius, total_impacted_suppliers, days)\n",
        "\n",
        "        return body\n",
        "\n",
        "    def _build_summary_section(self, alerts, impact_radius, total_impacted_suppliers, days):\n",
        "        \"\"\"Build the summary section of the email\"\"\"\n",
        "        body = \"üìä ENHANCED IMPACT ANALYSIS SUMMARY:\\n\"\n",
        "        body += f\"{'='*60}\\n\"\n",
        "        body += f\"üö® Total Impacted Suppliers: {total_impacted_suppliers}\\n\"\n",
        "        body += f\"üè≠ Total Monitored Suppliers: {len(self.suppliers)}\\n\"\n",
        "        body += f\"‚è∞ Monitoring Period: {days} days\\n\"\n",
        "        if len(self.suppliers) > 0:\n",
        "            body += f\"üìà Impact Rate: {(total_impacted_suppliers/len(self.suppliers)*100):.1f}% of supplier base\\n\"\n",
        "\n",
        "        # Event type statistics\n",
        "        event_type_stats = {}\n",
        "        alert_level_stats = {}\n",
        "        for alert in alerts:\n",
        "            event_type = alert['event_type']\n",
        "            alert_level = alert['alert_level']\n",
        "            event_type_stats[event_type] = event_type_stats.get(event_type, 0) + 1\n",
        "            alert_level_stats[alert_level] = alert_level_stats.get(alert_level, 0) + 1\n",
        "\n",
        "        body += f\"\\nüìà EVENT TYPE BREAKDOWN:\\n\"\n",
        "        for event_type, count in event_type_stats.items():\n",
        "            body += f\"   ‚Ä¢ {event_type}: {count} events\\n\"\n",
        "\n",
        "        body += f\"\\nüö® ALERT LEVEL BREAKDOWN:\\n\"\n",
        "        for alert_level, count in alert_level_stats.items():\n",
        "            emoji = {'Red': 'üî¥', 'Orange': 'üü†', 'Yellow': 'üü°', 'Green': 'üü¢'}.get(alert_level, '‚ö™')\n",
        "            body += f\"   {emoji} {alert_level}: {count} alerts\\n\"\n",
        "\n",
        "        body += f\"\\n{'='*80}\\n\"\n",
        "        body += \"ü§ñ Enhanced Automated GDACS Supplier Impact Analysis System\\n\"\n",
        "        body += \"üì° Data sources: GDACS RSS (Enhanced), USGS, Google Maps Geocoding\\n\"\n",
        "        body += \"üîß Complete GDACS attribute extraction with backup data sources\\n\"\n",
        "        body += \"‚ö†Ô∏è Please verify all information and contact suppliers directly.\\n\"\n",
        "        body += \"üîÑ Recommended: Activate backup suppliers for affected categories.\\n\"\n",
        "\n",
        "        return body\n",
        "\n",
        "    def _count_total_impacted_suppliers(self, alerts, impact_radius):\n",
        "        \"\"\"Count total impacted suppliers across all alerts\"\"\"\n",
        "        total = 0\n",
        "        for alert in alerts:\n",
        "            coords = alert['coordinates']\n",
        "            if coords['latitude'] and coords['longitude']:\n",
        "                impacted = self.analyze_supplier_impact(coords['latitude'], coords['longitude'], impact_radius)\n",
        "                total += len(impacted)\n",
        "        return total\n",
        "\n",
        "    def _send_no_alerts_notification(self, days, min_alert_level='Green'):\n",
        "        \"\"\"Send no alerts notification and save JSON\"\"\"\n",
        "        try:\n",
        "            # Generate JSON for no alerts case\n",
        "            json_data = self._generate_no_alerts_json(days, min_alert_level)\n",
        "            json_saved = self._save_json_report(json_data)\n",
        "\n",
        "            body = f\"üü¢ ENHANCED GDACS SUPPLIER STATUS: ALL CLEAR\\n\"\n",
        "            body += f\"{'='*60}\\n\"\n",
        "            body += f\"üìÖ Report Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "            body += f\"‚è∞ Monitoring Period: Past {days} days\\n\"\n",
        "            body += f\"üö® Alert Level Filter: {self._get_alert_level_description(min_alert_level)}\\n\"\n",
        "            body += f\"üè≠ Monitored Suppliers: {len(self.suppliers)}\\n\"\n",
        "            body += f\"‚úÖ No significant disasters detected at {min_alert_level}+ level\\n\"\n",
        "            body += f\"üåç Global disaster monitoring is active\\n\"\n",
        "            body += f\"üè≠ All suppliers are currently safe from disasters\\n\"\n",
        "\n",
        "            msg = MIMEText(body, 'plain', 'utf-8')\n",
        "            msg['Subject'] = Header(f\"üü¢ Enhanced Supplier Status: All Clear ({days} days, {min_alert_level}+ level)\", 'utf-8')\n",
        "            msg['From'] = formataddr((\"Enhanced GDACS Supplier Impact System\", self.email_config['email']))\n",
        "            msg['To'] = formataddr((\"Supply Chain Manager\", self.email_config['recipient']))\n",
        "\n",
        "            server = smtplib.SMTP(self.email_config['server'], self.email_config['port'])\n",
        "            server.starttls()\n",
        "            server.login(self.email_config['email'], self.email_config['password'])\n",
        "            server.sendmail(self.email_config['email'], self.email_config['recipient'], msg.as_string())\n",
        "            server.quit()\n",
        "\n",
        "            print(\"üìß Enhanced 'All Clear' notification sent!\")\n",
        "            if json_saved:\n",
        "                print(\"üíæ JSON report saved successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to send notification: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _generate_json_report(self, alerts, impact_radius, days, min_alert_level='Green'):\n",
        "        \"\"\"Generate comprehensive JSON report\"\"\"\n",
        "        report_data = {\n",
        "            \"report_metadata\": {\n",
        "                \"generation_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"system_name\": \"Enhanced GDACS Supplier Impact Analysis System\",\n",
        "                \"version\": \"2.0\",\n",
        "                \"monitoring_period_days\": days,\n",
        "                \"minimum_alert_level\": min_alert_level,\n",
        "                \"alert_level_description\": self._get_alert_level_description(min_alert_level),\n",
        "                \"impact_analysis_radius_km\": impact_radius,\n",
        "                \"total_disasters\": len(alerts),\n",
        "                \"total_monitored_suppliers\": len(self.suppliers)\n",
        "            },\n",
        "            \"system_statistics\": {\n",
        "                \"geocoded_suppliers\": len([s for s in self.suppliers if s['geocoded']]),\n",
        "                \"total_impacted_suppliers\": self._count_total_impacted_suppliers(alerts, impact_radius),\n",
        "                \"impact_rate_percentage\": (self._count_total_impacted_suppliers(alerts, impact_radius) / len(self.suppliers) * 100) if len(self.suppliers) > 0 else 0\n",
        "            },\n",
        "            \"disaster_alerts\": [],\n",
        "            \"supplier_impact_analysis\": {},\n",
        "            \"event_statistics\": {\n",
        "                \"by_event_type\": {},\n",
        "                \"by_alert_level\": {},\n",
        "                \"by_country\": {}\n",
        "            },\n",
        "            \"all_suppliers\": []\n",
        "        }\n",
        "\n",
        "        # Add all suppliers information\n",
        "        for supplier in self.suppliers:\n",
        "            supplier_data = {\n",
        "                \"id\": supplier['id'],\n",
        "                \"name\": supplier['name'],\n",
        "                \"address\": supplier['address'],\n",
        "                \"country\": supplier['country'],\n",
        "                \"contact_person\": supplier['contact_person'],\n",
        "                \"phone\": supplier['phone'],\n",
        "                \"email\": supplier['email'],\n",
        "                \"product_category\": supplier['product_category'],\n",
        "                \"critical_level\": supplier['critical_level'],\n",
        "                \"type\": supplier['type'],\n",
        "                \"coordinates\": {\n",
        "                    \"latitude\": supplier['latitude'],\n",
        "                    \"longitude\": supplier['longitude'],\n",
        "                    \"geocoded\": supplier['geocoded']\n",
        "                }\n",
        "            }\n",
        "            report_data[\"all_suppliers\"].append(supplier_data)\n",
        "\n",
        "        # Process each disaster alert\n",
        "        for i, alert in enumerate(alerts):\n",
        "            alert_data = {\n",
        "                \"alert_id\": i + 1,\n",
        "                \"basic_info\": {\n",
        "                    \"title\": alert['title'],\n",
        "                    \"description\": alert['description'],\n",
        "                    \"event_type\": alert['event_type'],\n",
        "                    \"event_type_short\": alert['event_type_short'],\n",
        "                    \"alert_level\": alert['alert_level'],\n",
        "                    \"country\": alert['country'],\n",
        "                    \"location_name\": alert.get('location_name', 'Unknown Location'),\n",
        "                    \"publication_date\": alert['pub_date'],\n",
        "                    \"source\": alert['source']\n",
        "                },\n",
        "                \"coordinates\": alert['coordinates'],\n",
        "                \"additional_attributes\": {\n",
        "                    \"event_id\": alert.get('event_id'),\n",
        "                    \"event_name\": alert.get('event_name'),\n",
        "                    \"severity\": alert.get('severity'),\n",
        "                    \"population\": alert.get('population'),\n",
        "                    \"vulnerability\": alert.get('vulnerability'),\n",
        "                    \"from_date\": alert.get('from_date').strftime('%Y-%m-%d %H:%M:%S') if alert.get('from_date') else None,\n",
        "                    \"to_date\": alert.get('to_date').strftime('%Y-%m-%d %H:%M:%S') if alert.get('to_date') else None,\n",
        "                    \"duration_in_week\": alert.get('duration_in_week'),\n",
        "                    \"is_current\": alert.get('is_current'),\n",
        "                    \"temporary\": alert.get('temporary'),\n",
        "                    \"magnitude\": alert.get('magnitude'),\n",
        "                    \"depth\": alert.get('depth')\n",
        "                },\n",
        "                \"links\": {\n",
        "                    \"source_link\": alert.get('link', ''),\n",
        "                    \"icon_url\": alert.get('icon_url', ''),\n",
        "                    \"google_maps\": f\"https://maps.google.com/?q={alert['coordinates']['latitude']},{alert['coordinates']['longitude']}\" if alert['coordinates']['latitude'] and alert['coordinates']['longitude'] else \"\"\n",
        "                },\n",
        "                \"impacted_suppliers\": []\n",
        "            }\n",
        "\n",
        "            # Analyze supplier impact for this disaster\n",
        "            if alert['coordinates']['latitude'] and alert['coordinates']['longitude']:\n",
        "                impacted_suppliers = self.analyze_supplier_impact(\n",
        "                    alert['coordinates']['latitude'],\n",
        "                    alert['coordinates']['longitude'],\n",
        "                    impact_radius\n",
        "                )\n",
        "\n",
        "                # Group suppliers by impact level\n",
        "                impact_groups = {}\n",
        "                for supplier in impacted_suppliers:\n",
        "                    level = supplier['impact_level']\n",
        "                    if level not in impact_groups:\n",
        "                        impact_groups[level] = []\n",
        "\n",
        "                    supplier_impact_data = {\n",
        "                        \"supplier_id\": supplier['id'],\n",
        "                        \"name\": supplier['name'],\n",
        "                        \"address\": supplier['address'],\n",
        "                        \"country\": supplier['country'],\n",
        "                        \"contact_info\": {\n",
        "                            \"contact_person\": supplier['contact_person'],\n",
        "                            \"phone\": supplier['phone'],\n",
        "                            \"email\": supplier['email']\n",
        "                        },\n",
        "                        \"business_info\": {\n",
        "                            \"product_category\": supplier['product_category'],\n",
        "                            \"critical_level\": supplier['critical_level'],\n",
        "                            \"type\": supplier['type']\n",
        "                        },\n",
        "                        \"coordinates\": {\n",
        "                            \"latitude\": supplier['latitude'],\n",
        "                            \"longitude\": supplier['longitude']\n",
        "                        },\n",
        "                        \"impact_analysis\": {\n",
        "                            \"distance_km\": round(supplier['distance_km'], 2),\n",
        "                            \"impact_level\": supplier['impact_level']\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    impact_groups[level].append(supplier_impact_data)\n",
        "                    alert_data[\"impacted_suppliers\"].append(supplier_impact_data)\n",
        "\n",
        "                alert_data[\"impact_summary\"] = {\n",
        "                    \"total_impacted\": len(impacted_suppliers),\n",
        "                    \"by_impact_level\": {level: len(suppliers) for level, suppliers in impact_groups.items()}\n",
        "                }\n",
        "            else:\n",
        "                alert_data[\"impact_summary\"] = {\n",
        "                    \"total_impacted\": 0,\n",
        "                    \"reason\": \"No coordinates available for impact analysis\"\n",
        "                }\n",
        "\n",
        "            report_data[\"disaster_alerts\"].append(alert_data)\n",
        "\n",
        "            # Update statistics\n",
        "            event_type = alert['event_type']\n",
        "            alert_level = alert['alert_level']\n",
        "            country = alert['country']\n",
        "\n",
        "            report_data[\"event_statistics\"][\"by_event_type\"][event_type] = \\\n",
        "                report_data[\"event_statistics\"][\"by_event_type\"].get(event_type, 0) + 1\n",
        "            report_data[\"event_statistics\"][\"by_alert_level\"][alert_level] = \\\n",
        "                report_data[\"event_statistics\"][\"by_alert_level\"].get(alert_level, 0) + 1\n",
        "            report_data[\"event_statistics\"][\"by_country\"][country] = \\\n",
        "                report_data[\"event_statistics\"][\"by_country\"].get(country, 0) + 1\n",
        "\n",
        "        return report_data\n",
        "\n",
        "    def _generate_no_alerts_json(self, days, min_alert_level='Green'):\n",
        "        \"\"\"Generate JSON report for no alerts case\"\"\"\n",
        "        report_data = {\n",
        "            \"report_metadata\": {\n",
        "                \"generation_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"system_name\": \"Enhanced GDACS Supplier Impact Analysis System\",\n",
        "                \"version\": \"2.0\",\n",
        "                \"monitoring_period_days\": days,\n",
        "                \"minimum_alert_level\": min_alert_level,\n",
        "                \"alert_level_description\": self._get_alert_level_description(min_alert_level),\n",
        "                \"total_disasters\": 0,\n",
        "                \"total_monitored_suppliers\": len(self.suppliers),\n",
        "                \"status\": \"ALL_CLEAR\"\n",
        "            },\n",
        "            \"system_statistics\": {\n",
        "                \"geocoded_suppliers\": len([s for s in self.suppliers if s['geocoded']]),\n",
        "                \"total_impacted_suppliers\": 0,\n",
        "                \"impact_rate_percentage\": 0\n",
        "            },\n",
        "            \"disaster_alerts\": [],\n",
        "            \"supplier_impact_analysis\": {\n",
        "                \"summary\": f\"No disasters detected at {min_alert_level}+ level in the monitoring period\"\n",
        "            },\n",
        "            \"event_statistics\": {\n",
        "                \"by_event_type\": {},\n",
        "                \"by_alert_level\": {},\n",
        "                \"by_country\": {}\n",
        "            },\n",
        "            \"all_suppliers\": []\n",
        "        }\n",
        "\n",
        "        # Add all suppliers information\n",
        "        for supplier in self.suppliers:\n",
        "            supplier_data = {\n",
        "                \"id\": supplier['id'],\n",
        "                \"name\": supplier['name'],\n",
        "                \"address\": supplier['address'],\n",
        "                \"country\": supplier['country'],\n",
        "                \"contact_person\": supplier['contact_person'],\n",
        "                \"phone\": supplier['phone'],\n",
        "                \"email\": supplier['email'],\n",
        "                \"product_category\": supplier['product_category'],\n",
        "                \"critical_level\": supplier['critical_level'],\n",
        "                \"type\": supplier['type'],\n",
        "                \"coordinates\": {\n",
        "                    \"latitude\": supplier['latitude'],\n",
        "                    \"longitude\": supplier['longitude'],\n",
        "                    \"geocoded\": supplier['geocoded']\n",
        "                },\n",
        "                \"status\": \"SAFE\"\n",
        "            }\n",
        "            report_data[\"all_suppliers\"].append(supplier_data)\n",
        "\n",
        "        return report_data\n",
        "\n",
        "    def _save_json_report(self, json_data):\n",
        "        \"\"\"Save JSON report to file\"\"\"\n",
        "        try:\n",
        "            # Generate filename with timestamp\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            filename = f\"gdacs_supplier_impact_report_{timestamp}.json\"\n",
        "\n",
        "            # Save to current directory (Google Colab)\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üíæ JSON report saved as: {filename}\")\n",
        "            print(f\"üìä Report contains:\")\n",
        "            print(f\"   ‚Ä¢ {json_data['report_metadata']['total_disasters']} disaster alerts\")\n",
        "            print(f\"   ‚Ä¢ {json_data['report_metadata']['total_monitored_suppliers']} suppliers\")\n",
        "            print(f\"   ‚Ä¢ {json_data['system_statistics']['total_impacted_suppliers']} impacted suppliers\")\n",
        "            print(f\"   ‚Ä¢ Monitoring period: {json_data['report_metadata']['monitoring_period_days']} days\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to save JSON report: {e}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main program\"\"\"\n",
        "    print(\"üè≠ ENHANCED GDACS SUPPLIER IMPACT ANALYSIS SYSTEM\")\n",
        "    print(\"=\"*90)\n",
        "    print(\"üìß Monitors disasters with complete GDACS data and analyzes supplier impact\")\n",
        "    print(\"üîç Enhanced Features:\")\n",
        "    print(\"   ‚Ä¢ Complete GDACS attribute extraction (all 25+ fields)\")\n",
        "    print(\"   ‚Ä¢ Multiple coordinate parsing methods\")\n",
        "    print(\"   ‚Ä¢ Enhanced event classification\")\n",
        "    print(\"   ‚Ä¢ Backup data sources (USGS)\")\n",
        "    print(\"   ‚Ä¢ Improved geocoding and mapping\")\n",
        "    print(\"   ‚Ä¢ Supplier type analysis support\")\n",
        "    print(\"   ‚Ä¢ User-defined monitoring period\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    # Initialize enhanced system\n",
        "    system = EnhancedGDACSSupplierImpactSystem()\n",
        "\n",
        "    # Check supplier CSV file\n",
        "    csv_file = \"merged_full_dataset.csv\"\n",
        "    if not os.path.exists(csv_file):\n",
        "        print(f\"\\nüìù Supplier CSV file not found: {csv_file}\")\n",
        "        print(\"‚ùå Cannot proceed without supplier data\")\n",
        "        print(\"Please ensure your CSV file is named 'merged_full_dataset.csv' and contains the required columns:\")\n",
        "        print(\"   id, name, address, country, contact_person, phone, email, product_category, critical_level, type\")\n",
        "        return\n",
        "\n",
        "    # Load supplier data\n",
        "    print(f\"\\nüè≠ Loading suppliers from {csv_file}...\")\n",
        "    print(\"üîç Validating CSV format...\")\n",
        "    system.validate_csv_format(csv_file)\n",
        "\n",
        "    if not system.load_suppliers_from_csv(csv_file):\n",
        "        print(\"‚ùå Failed to load supplier data\")\n",
        "        print(\"\\nüîß TROUBLESHOOTING:\")\n",
        "        print(\"   1. Check if addresses are properly quoted or use alternative delimiter\")\n",
        "        print(\"   2. Ensure all required fields (id, name, address, country) are present\")\n",
        "        print(\"   3. Use UTF-8 encoding when saving the CSV file\")\n",
        "        return\n",
        "\n",
        "    # Gmail configuration\n",
        "    print(\"\\nüìß Gmail Configuration:\")\n",
        "    gmail = input(\"üìß Enter your Gmail address: \").strip()\n",
        "    password = input(\"üîë Enter your Gmail App Password: \").strip()\n",
        "    recipient = input(\"üì• Enter recipient email address: \").strip()\n",
        "\n",
        "    if not gmail or not password or not recipient:\n",
        "        print(\"‚ùå All fields are required!\")\n",
        "        return\n",
        "\n",
        "    system.setup_gmail(gmail, password, recipient)\n",
        "\n",
        "    # Google Maps API configuration\n",
        "    print(\"\\nüó∫Ô∏è Google Maps API Configuration:\")\n",
        "    print(\"üìù Required for address geocoding (converting addresses to coordinates)\")\n",
        "    print(\"   1. Go to https://console.cloud.google.com/\")\n",
        "    print(\"   2. Enable 'Geocoding API'\")\n",
        "    print(\"   3. Create an API key\")\n",
        "\n",
        "    api_key = input(\"üîë Enter your Google Maps API key: \").strip()\n",
        "\n",
        "    if api_key:\n",
        "        system.setup_google_maps(api_key)\n",
        "\n",
        "        # Address geocoding\n",
        "        print(\"\\nüó∫Ô∏è Converting supplier addresses to coordinates...\")\n",
        "        geocoded = system.geocode_suppliers()\n",
        "\n",
        "        if not geocoded:\n",
        "            print(\"‚ö†Ô∏è Geocoding failed - impact analysis will be limited\")\n",
        "    else:\n",
        "        print(\"‚ùå Google Maps API key required for supplier impact analysis\")\n",
        "        return\n",
        "\n",
        "    # Test email\n",
        "    print(\"\\nüì¨ Testing email connection...\")\n",
        "    if not system.send_test_email():\n",
        "        print(\"‚ùå Email test failed. Please check your settings.\")\n",
        "        return\n",
        "\n",
        "    # User-defined monitoring period\n",
        "    print(\"\\n‚è∞ Monitoring Period Configuration:\")\n",
        "    print(\"üìù Set how many days back to search for disasters\")\n",
        "    days_input = input(\"üìÖ Enter number of days to monitor (default: 7): \").strip()\n",
        "\n",
        "    try:\n",
        "        monitoring_days = int(days_input) if days_input else 7\n",
        "        if monitoring_days < 1:\n",
        "            print(\"‚ö†Ô∏è Days must be at least 1, using default value: 7\")\n",
        "            monitoring_days = 7\n",
        "        elif monitoring_days > 30:\n",
        "            print(\"‚ö†Ô∏è Maximum 30 days supported, setting to 30\")\n",
        "            monitoring_days = 30\n",
        "    except ValueError:\n",
        "        print(\"‚ö†Ô∏è Invalid input, using default value: 7 days\")\n",
        "        monitoring_days = 7\n",
        "\n",
        "    print(f\"üìä Monitoring period set to: {monitoring_days} days\")\n",
        "\n",
        "    # Alert level configuration\n",
        "    print(\"\\nüö® Alert Level Configuration:\")\n",
        "    print(\"üìù Choose minimum alert level to monitor (GDACS Standard)\")\n",
        "    print(\"   1. üü¢ Green and above (All alerts - includes minor events)\")\n",
        "    print(\"   2. üü† Orange and above (High to severe events)\")\n",
        "    print(\"   3. üî¥ Red only (Severe events only)\")\n",
        "\n",
        "    level_choice = input(\"üî¢ Enter your choice (1-3, default: 1): \").strip()\n",
        "\n",
        "    level_mapping = {\n",
        "        '1': 'Green',\n",
        "        '2': 'Orange',\n",
        "        '3': 'Red'\n",
        "    }\n",
        "\n",
        "    min_alert_level = level_mapping.get(level_choice, 'Green')\n",
        "    print(f\"üö® Alert level filter set to: {system._get_alert_level_description(min_alert_level)}\")\n",
        "\n",
        "    # Get enhanced disaster alerts\n",
        "    print(f\"\\nüîç Fetching enhanced disaster alerts from past {monitoring_days} days...\")\n",
        "    alerts = system.get_enhanced_gdacs_alerts(days=monitoring_days, min_alert_level=min_alert_level)\n",
        "\n",
        "    # Set impact radius\n",
        "    impact_radius = input(f\"\\nüìè Enter impact analysis radius in km (default: 100): \").strip()\n",
        "    try:\n",
        "        impact_radius = int(impact_radius) if impact_radius else 100\n",
        "    except:\n",
        "        impact_radius = 100\n",
        "\n",
        "    # Send enhanced supplier impact analysis report\n",
        "    print(f\"\\nüìä Analyzing enhanced supplier impact (radius: {impact_radius}km, period: {monitoring_days} days, level: {min_alert_level}+)...\")\n",
        "    success = system.send_enhanced_supplier_impact_alert(alerts, impact_radius, monitoring_days, min_alert_level)\n",
        "\n",
        "    if success:\n",
        "        print(\"‚úÖ Enhanced supplier impact analysis completed successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå Enhanced supplier impact analysis encountered errors.\")\n",
        "\n",
        "    print(f\"\\nüìà Enhanced Summary:\")\n",
        "    print(f\"   üìß Email system: ‚úÖ Working\")\n",
        "    print(f\"   üó∫Ô∏è Google Maps API: ‚úÖ Working\")\n",
        "    print(f\"   üè≠ Suppliers loaded: {len(system.suppliers)}\")\n",
        "    print(f\"   ‚è∞ Monitoring period: {monitoring_days} days\")\n",
        "    print(f\"   üö® Alert level filter: {min_alert_level}+ ({system._get_alert_level_description(min_alert_level)})\")\n",
        "    print(f\"   üåç Enhanced disasters found: {len(alerts)}\")\n",
        "    print(f\"   üîß GDACS attributes extracted: ‚úÖ Complete\")\n",
        "    print(f\"   üì¨ Enhanced report sent: {'‚úÖ Yes' if success else '‚ùå No'}\")\n",
        "    print(f\"   üíæ JSON report saved: ‚úÖ Yes\")\n",
        "    print(f\"\\nüìÇ Files generated:\")\n",
        "    print(f\"   ‚Ä¢ JSON report: gdacs_supplier_impact_report_[timestamp].json\")\n",
        "    print(f\"   ‚Ä¢ Location: Current Google Colab directory\")\n",
        "    print(f\"\\nüîç JSON report contains:\")\n",
        "    print(f\"   ‚Ä¢ Complete disaster alert details\")\n",
        "    print(f\"   ‚Ä¢ Full supplier impact analysis\")\n",
        "    print(f\"   ‚Ä¢ Statistical summaries\")\n",
        "    print(f\"   ‚Ä¢ All supplier information\")\n",
        "    print(f\"   ‚Ä¢ Coordinates and mapping data\")\n",
        "    print(f\"   ‚Ä¢ Alert level filtering information\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nüëã Program interrupted by user. Goodbye!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Unexpected error: {e}\")\n",
        "        print(\"Please restart the program.\")"
      ]
    }
  ]
}